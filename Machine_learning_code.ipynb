{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "zYfO6WtwBtsk"
      },
      "outputs": [],
      "source": [
        "!apt-get update -qq > /dev/null\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://dlcdn.apache.org/spark/spark-3.2.3/spark-3.2.3-bin-hadoop2.7.tgz\n",
        "!tar xf spark-3.2.3-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import re"
      ],
      "metadata": {
        "id": "vx3DYEqBsADL"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.2.3-bin-hadoop2.7\"\n",
        "\n",
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "from pyspark import SparkContext\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "sc = SparkContext(appName=\"YourTest\", master=\"local[*]\")\n",
        "spark = SparkSession.builder.appName(\"YourTest\").master(\"local[2]\").config('spark.ui.port', random.randrange(4000,5000)).getOrCreate()"
      ],
      "metadata": {
        "id": "HyWjPMpzDYSX"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get the raw csv data\n",
        "file1Name = \"Science_data.csv\"\n",
        "file2Name = \"arts_data.csv\"\n",
        "\n",
        "df = spark.read.csv(file1Name,inferSchema=True)\n",
        "df = df.toDF('id','Tweet','time').cache()\n",
        "df1 = df.rdd.map(lambda x: x[1])\n",
        "\n",
        "df = spark.read.csv(file2Name,inferSchema=True)\n",
        "df = df.toDF('id','Tweet','time').cache()\n",
        "df2 = df.rdd.map(lambda x: x[1])\n"
      ],
      "metadata": {
        "id": "DiudQE3EMmwu"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df.take(10)"
      ],
      "metadata": {
        "id": "FSD4zB8VSufa"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def runLoop(data):\n",
        "    model = {}\n",
        "    i = 0\n",
        "    for row in data:\n",
        "      i = i+1\n",
        "      row = row[1:-1].replace(\"'\",'').replace(\"[\",'').replace(\"]\",'').split(', ')\n",
        "      for j in range(len(row)):\n",
        "        word = row[j]\n",
        "        if word in model.keys():\n",
        "          model[word].append(i)\n",
        "        else:\n",
        "          model[word] = [i]\n",
        "\n",
        "    return model.items()\n",
        "data1 = df1.coalesce(1)\n",
        "model1 = data1.mapPartitions(runLoop)\n",
        "wordMap1 = model1.collect()\n",
        "data2 = df2.coalesce(1)\n",
        "model2 = data2.mapPartitions(runLoop)\n",
        "wordMap2 = model2.collect()"
      ],
      "metadata": {
        "id": "h65A1sFMNlDD"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "totalRow1 = data1.count()\n",
        "totalRow2 = data2.count()\n",
        "print(len(wordMap1))\n",
        "print(totalRow1)\n",
        "print(len(wordMap2))\n",
        "print(totalRow2)"
      ],
      "metadata": {
        "id": "apTpY3hVGYif",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d46e6bcc-392a-48e8-c8a8-58af0648271a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6623\n",
            "2102\n",
            "9870\n",
            "3433\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wordDict = {}\n",
        "totalWords1 = len(wordMap1)\n",
        "\n",
        "for i in range(totalWords1):\n",
        "  word = wordMap1[i][0]\n",
        "  wordDict[word] = i\n",
        "\n",
        "print(len(wordDict))\n",
        "totalWords2 = len(wordMap2)\n",
        "k = totalWords1\n",
        "for i in range(totalWords2):\n",
        "  word = wordMap2[i][0]\n",
        "  if word not in wordDict.keys():\n",
        "    wordDict[word] = k\n",
        "    k = k+1\n",
        "\n",
        "print(len(wordDict))"
      ],
      "metadata": {
        "id": "nHnPVgQnOTGu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d146d47-e3ee-4c3c-8de1-0fcbfe32f081"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6623\n",
            "13729\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "totalWords = len(wordDict)\n",
        "trainlength1 = int(totalRow1 * 0.8)\n",
        "testlength1 = totalRow1 - trainlength1\n",
        "trainlength2 = int(totalRow2 * 0.8)\n",
        "testlength2 = totalRow2 - trainlength2\n",
        "trainArray = np.zeros((trainlength1+trainlength2+1,totalWords))\n",
        "testArray = np.zeros((testlength1+testlength2,totalWords))\n",
        "print(trainlength1,trainlength2,testlength1,testlength2)\n",
        "print(trainArray.shape)"
      ],
      "metadata": {
        "id": "JC65lp9iUaxm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e87559f-92c5-4933-d565-1ff1aa690fc9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1681 2746 421 687\n",
            "(4428, 13729)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(totalWords1):\n",
        "  for j in range(len(wordMap1[i][1])):\n",
        "    word = wordDict[wordMap1[i][0]]\n",
        "    line = wordMap1[i][1][j]\n",
        "    # print(word,line)\n",
        "    if(line<trainlength1):\n",
        "      trainArray[line,word] = 1\n",
        "    else:\n",
        "      line = line - trainlength1 \n",
        "      testArray[line,word] = 1\n"
      ],
      "metadata": {
        "id": "uIdNg07vgAqF"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(trainlength2):\n",
        "  for j in range(len(wordMap2[i][1])):\n",
        "    word = wordDict[wordMap2[i][0]]\n",
        "    line = wordMap2[i][1][j] + trainlength1\n",
        "    # print(word,line)\n",
        "    if(line<trainArray.shape[0]):\n",
        "      trainArray[line,word] = 1\n",
        "    else:\n",
        "      line = line - trainlength1 - trainlength2\n",
        "      testArray[line,word] = 1 "
      ],
      "metadata": {
        "id": "vaHlE3UcVC8C"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize the feature probability\n",
        "\n",
        "featureProb = np.zeros((totalWords,4))\n",
        "trainData = pd.DataFrame(trainArray)\n",
        "ones = np.ones(trainlength1+1)\n",
        "zeros = np.zeros(trainlength2)\n",
        "onesZeros = np.concatenate((ones,zeros), axis=None)\n",
        "trainData['label'] = onesZeros\n",
        "print(trainData.shape)\n",
        "\n",
        "testData = pd.DataFrame(testArray)\n",
        "ones = np.ones(testlength1)\n",
        "zeros = np.zeros(testlength2)\n",
        "onesZeros = np.concatenate((ones,zeros), axis=None)\n",
        "testData['label'] = onesZeros\n",
        "print(testData.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cNH1ObMfsFZ",
        "outputId": "7f70e057-ec56-44ca-bdd8-81204911e076"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4428, 13730)\n",
            "(1108, 13730)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#get feature/word probability\n",
        "for j in range(totalWords):\n",
        "    featurej = list(trainData.groupby(j)['label'].apply(list).values)\n",
        "    \n",
        "    if(len(featurej) == 2):\n",
        "        total = len(featurej[1])\n",
        "        ones = np.sum(featurej[1])     \n",
        "        zeros = total - ones\n",
        "        featureProb[j, 0] = (zeros + 1) / (totalRow2 + 2)\n",
        "        featureProb[j, 1] = (ones + 1) / (totalRow1 + 3)\n",
        "    else:\n",
        "        featureProb[j, 0] = 1 / (totalRow2 + 2)\n",
        "        featureProb[j, 1] = 1 / (totalRow1 + 3)\n",
        "\n",
        "featureProb[:,2] = 1- featureProb[:,0]\n",
        "featureProb[:,3] = 1- featureProb[:,1]\n",
        "logFeatureProb = np.log2(featureProb)"
      ],
      "metadata": {
        "id": "tXqYZbxTskCF"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get training accuracy\n",
        "\n",
        "inputdata = trainData.iloc[:, 0:totalWords].to_numpy()\n",
        "inputdataPrime = 1 - trainData.iloc[:, 0:totalWords].to_numpy()\n",
        "probabzeros = np.multiply(inputdata, np.asmatrix(logFeatureProb[:,0]))\n",
        "probabones = np.multiply(inputdata, np.asmatrix(logFeatureProb[:,1]))\n",
        "probabzerosPrime = np.multiply(inputdataPrime, np.asmatrix(logFeatureProb[:,2]))\n",
        "probabonesPrime = np.multiply(inputdataPrime, np.asmatrix(logFeatureProb[:,3]))\n",
        "\n",
        "totalWords1 = trainData.shape[0]\n",
        "resultZero = np.zeros(totalWords1)\n",
        "resultOne = np.zeros(totalWords1)\n",
        "\n",
        "for j in range(totalWords1):\n",
        "    resultZero[j] = np.sum(probabzeros[j]) + np.sum(probabzerosPrime[j])\n",
        "    resultOne[j] = np.sum(probabones[j]) + np.sum(probabonesPrime[j])\n",
        "    \n",
        "outputLabel = (resultZero <= resultOne).astype(int)\n",
        "trainAccuracy = np.sum(outputLabel == trainData[\"label\"]) / trainData.shape[0] \n",
        "print(trainAccuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r6A0MtOXkHE8",
        "outputId": "b8e81926-1d0e-42d9-c225-a45ed44312db"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8010388437217706\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get testing accuracy\n",
        "\n",
        "inputdata = testData.iloc[:, 0:totalWords].to_numpy()\n",
        "inputdataPrime = 1 - testData.iloc[:, 0:totalWords].to_numpy()\n",
        "probabzeros = np.multiply(inputdata, np.asmatrix(logFeatureProb[:,0]))\n",
        "probabones = np.multiply(inputdata, np.asmatrix(logFeatureProb[:,1]))\n",
        "probabzerosPrime = np.multiply(inputdataPrime, np.asmatrix(logFeatureProb[:,2]))\n",
        "probabonesPrime = np.multiply(inputdataPrime, np.asmatrix(logFeatureProb[:,3]))\n",
        "\n",
        "totalWords2 = testData.shape[0]\n",
        "resultZero = np.zeros(totalWords2)\n",
        "resultOne = np.zeros(totalWords2)\n",
        "\n",
        "for j in range(totalWords2):\n",
        "    resultZero[j] = np.sum(probabzeros[j]) + np.sum(probabzerosPrime[j])\n",
        "    resultOne[j] = np.sum(probabones[j]) + np.sum(probabonesPrime[j])\n",
        "    \n",
        "outputLabel = (resultZero <= resultOne).astype(int)\n",
        "testAccuracy = np.sum(outputLabel == testData[\"label\"]) / testData.shape[0] \n",
        "print(testAccuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "INEccr1BU4y1",
        "outputId": "9b871238-855c-42e2-931a-3f68bcfa719d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7265342960288809\n"
          ]
        }
      ]
    }
  ]
}